{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load boston housing prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x = boston['data']\n",
    "N = x.shape[0]\n",
    "x = np.concatenate((np.ones((506,1)),x),axis=1) #add constant one feature - no bias needed\n",
    "d = x.shape[1]\n",
    "y = boston['target']\n",
    "\n",
    "idx = np.random.permutation(range(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2(A,B):\n",
    "    '''\n",
    "    Input: A is a Nxd matrix\n",
    "           B is a Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square\n",
    "    norm between A[i,:] and B[j,:]\n",
    "    i.e. dist[i,j] = ||A[i,:]-B[j,:]||^2\n",
    "    '''\n",
    "    A_norm = (A**2).sum(axis=1).reshape(A.shape[0],1)\n",
    "    B_norm = (B**2).sum(axis=1).reshape(1,B.shape[0])\n",
    "    dist = A_norm+B_norm-2*A.dot(B.transpose())\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Locally Reweighted Least Squares function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRLS(test_datum,x_train,y_train,tau,lam=1e-5):\n",
    "    '''\n",
    "    Input: test_datum is a dx1 test vector\n",
    "           x_train is the N_train x d design matrix\n",
    "           y_train is the N_train x 1 targets vector\n",
    "           tau is the local reweighting parameter\n",
    "           lam is the regularization parameter\n",
    "    output is y_hat the prediction on test_datum\n",
    "    '''\n",
    "    #1. Compute distance based weights\n",
    "    norm_x_minus_xi = l2(test_datum.T, x_train)[0,:].reshape(-1,1) \n",
    "    a = np.exp((-norm_x_minus_xi/(2*tau*tau)) - logsumexp(-norm_x_minus_xi/(2*tau*tau)))\n",
    "    A = np.identity(norm_x_minus_xi.shape[0])*a\n",
    "        \n",
    "    #2. Compute w_star\n",
    "    LHS = (np.matmul(x_train.T, np.matmul(A,x_train)) + (lam*np.identity(x_train.shape[1])))\n",
    "    RHS = np.matmul(x_train.T, np.matmul(A,y_train))\n",
    "    w_star = np.linalg.solve(LHS,RHS)\n",
    "\n",
    "    #3. Compute y_hat (prediction of y)\n",
    "    y_hat = np.matmul(test_datum.T, w_star)[0,0] \n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(x,y,taus,val_frac):\n",
    "    '''\n",
    "    Input: x is the N x d design matrix\n",
    "           y is the N x 1 targets vector    \n",
    "           taus is a vector of tau values to evaluate\n",
    "           val_frac is the fraction of examples to use as validation data\n",
    "    output is\n",
    "           a vector of training losses, one for each tau value\n",
    "           a vector of validation losses, one for each tau value\n",
    "    '''\n",
    "    #1. Split testing and training data & initialise variables\n",
    "    x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size=val_frac, random_state=69)\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_validation = y_validation.reshape(-1,1)\n",
    "    y_hat_train = []\n",
    "    y_hat_validation = []\n",
    "    \n",
    "    print(y_train)\n",
    "    \n",
    "    #2. Iterate for all values of tau and for all x_train and x_validation\n",
    "    i=0\n",
    "    for tau in taus:\n",
    "        for test_datum in x_train:\n",
    "            test_datum = test_datum.reshape(-1,1)\n",
    "            y_hat_curr = LRLS(test_datum,x_train,y_train,tau) #returns a (1,1)\n",
    "            y_hat_train.append(y_hat_curr)\n",
    "        i+=1\n",
    "        print(\"Train iteration #\",i,\"from a total\",len(taus))        \n",
    "    np_y_hat_train = np.array(y_hat_train).reshape(-1,x_train.shape[0])\n",
    "\n",
    "    print(np_y_hat_train)\n",
    "    \n",
    "    i=0\n",
    "    for tau in taus:\n",
    "        for test_datum in x_validation:\n",
    "            test_datum = test_datum.reshape(-1,1)\n",
    "            y_hat_curr = LRLS(test_datum,x_train,y_train,tau) #returns a (1,1)\n",
    "            y_hat_validation.append(y_hat_curr)\n",
    "        i+=1\n",
    "        print(\"Validation iteration #\",i,\"from a total\",len(taus)) \n",
    "    np_y_hat_validation = np.array(y_hat_validation).reshape(-1,x_validation.shape[0])\n",
    "    \n",
    "    #3. Compute the training and validation losses\n",
    "    print(y_train.shape, np_y_hat_train.shape)\n",
    "    train_losses = (1/y_train.shape[0]) * np.sum(0.5*np.square(y_train.T - np_y_hat_train),1) #one value for each tau\n",
    "    validation_losses = (1/y_validation.shape[0]) * np.sum(0.5*np.square(y_validation.T - np_y_hat_validation),1) #one value for tau\n",
    "    \n",
    "    return train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.9]\n",
      " [14.5]\n",
      " [32. ]\n",
      " [41.7]\n",
      " [19.3]\n",
      " [48.3]\n",
      " [44.8]\n",
      " [20.1]\n",
      " [20. ]\n",
      " [16.8]\n",
      " [29.8]\n",
      " [50. ]\n",
      " [25. ]\n",
      " [19.6]\n",
      " [23.8]\n",
      " [16.6]\n",
      " [13.4]\n",
      " [22.2]\n",
      " [22.5]\n",
      " [39.8]\n",
      " [50. ]\n",
      " [16.2]\n",
      " [22.6]\n",
      " [23.7]\n",
      " [25. ]\n",
      " [12.7]\n",
      " [10.9]\n",
      " [17.8]\n",
      " [23.1]\n",
      " [18.5]\n",
      " [25.3]\n",
      " [21.4]\n",
      " [15.4]\n",
      " [27.5]\n",
      " [22. ]\n",
      " [17. ]\n",
      " [ 9.7]\n",
      " [24.2]\n",
      " [23.1]\n",
      " [22.2]\n",
      " [34.9]\n",
      " [20.4]\n",
      " [22.8]\n",
      " [25. ]\n",
      " [13.4]\n",
      " [32.7]\n",
      " [21.6]\n",
      " [12.7]\n",
      " [22.6]\n",
      " [30.1]\n",
      " [31.7]\n",
      " [31.5]\n",
      " [22.7]\n",
      " [14.1]\n",
      " [ 6.3]\n",
      " [50. ]\n",
      " [19.6]\n",
      " [12. ]\n",
      " [15.3]\n",
      " [20.2]\n",
      " [24.5]\n",
      " [22.9]\n",
      " [27. ]\n",
      " [21.1]\n",
      " [20.8]\n",
      " [14.4]\n",
      " [10.5]\n",
      " [19.8]\n",
      " [50. ]\n",
      " [11.7]\n",
      " [20. ]\n",
      " [10.2]\n",
      " [22.7]\n",
      " [14.6]\n",
      " [17.5]\n",
      " [19.4]\n",
      " [18.2]\n",
      " [36.2]\n",
      " [14.4]\n",
      " [17.1]\n",
      " [ 7. ]\n",
      " [22. ]\n",
      " [23.9]\n",
      " [23.9]\n",
      " [28.2]\n",
      " [23.2]\n",
      " [29.6]\n",
      " [13.1]\n",
      " [13.9]\n",
      " [22.9]\n",
      " [18.2]\n",
      " [22.5]\n",
      " [13.8]\n",
      " [20. ]\n",
      " [18.8]\n",
      " [ 5. ]\n",
      " [20.6]\n",
      " [10.4]\n",
      " [23.2]\n",
      " [11. ]\n",
      " [13. ]\n",
      " [ 5.6]\n",
      " [18.4]\n",
      " [33.8]\n",
      " [13.8]\n",
      " [19.6]\n",
      " [15.2]\n",
      " [24.1]\n",
      " [17.7]\n",
      " [23.2]\n",
      " [14.9]\n",
      " [19.2]\n",
      " [13.5]\n",
      " [20.5]\n",
      " [16.7]\n",
      " [28.7]\n",
      " [25.2]\n",
      " [20.4]\n",
      " [16.5]\n",
      " [19.6]\n",
      " [15.7]\n",
      " [25. ]\n",
      " [33.2]\n",
      " [27.9]\n",
      " [13.8]\n",
      " [21.6]\n",
      " [12.6]\n",
      " [35.4]\n",
      " [18.5]\n",
      " [23.9]\n",
      " [14.3]\n",
      " [11.7]\n",
      " [17.4]\n",
      " [50. ]\n",
      " [32. ]\n",
      " [32.5]\n",
      " [17.8]\n",
      " [34.9]\n",
      " [16.5]\n",
      " [16.7]\n",
      " [19.5]\n",
      " [15. ]\n",
      " [15.4]\n",
      " [20.5]\n",
      " [21.7]\n",
      " [24.4]\n",
      " [22.3]\n",
      " [30.5]\n",
      " [29. ]\n",
      " [17.8]\n",
      " [ 7.2]\n",
      " [18.6]\n",
      " [18.3]\n",
      " [50. ]\n",
      " [28.1]\n",
      " [18.9]\n",
      " [19.7]\n",
      " [24.4]\n",
      " [33.1]\n",
      " [15. ]\n",
      " [21.4]\n",
      " [11.3]\n",
      " [42.8]\n",
      " [31.1]\n",
      " [38.7]\n",
      " [34.9]\n",
      " [22.3]\n",
      " [10.8]\n",
      " [42.3]\n",
      " [17.3]\n",
      " [44. ]\n",
      " [14.5]\n",
      " [23.3]\n",
      " [24.7]\n",
      " [ 8.4]\n",
      " [22.4]\n",
      " [27.5]\n",
      " [22.8]\n",
      " [26.7]\n",
      " [18.7]\n",
      " [29.6]\n",
      " [14.9]\n",
      " [21.7]\n",
      " [23. ]\n",
      " [35.2]\n",
      " [26.4]\n",
      " [21.9]\n",
      " [19.8]\n",
      " [28.5]\n",
      " [45.4]\n",
      " [32.2]\n",
      " [21.8]\n",
      " [24.7]\n",
      " [ 8.3]\n",
      " [16.3]\n",
      " [24.3]\n",
      " [17.1]\n",
      " [20.6]\n",
      " [14.1]\n",
      " [43.8]\n",
      " [20.9]\n",
      " [19.8]\n",
      " [24.5]\n",
      " [15.6]\n",
      " [19.4]\n",
      " [31.6]\n",
      " [20.7]\n",
      " [17.2]\n",
      " [13.8]\n",
      " [50. ]\n",
      " [18.2]\n",
      " [25. ]\n",
      " [ 7.4]\n",
      " [43.5]\n",
      " [19.4]\n",
      " [20. ]\n",
      " [20.4]\n",
      " [17.4]\n",
      " [20.3]\n",
      " [16.8]\n",
      " [ 8.3]\n",
      " [24. ]\n",
      " [29.9]\n",
      " [21.7]\n",
      " [ 9.6]\n",
      " [ 8.7]\n",
      " [20.6]\n",
      " [21.4]\n",
      " [23.8]\n",
      " [12.1]\n",
      " [20.3]\n",
      " [50. ]\n",
      " [22. ]\n",
      " [21.5]\n",
      " [11.5]\n",
      " [14.9]\n",
      " [29.1]\n",
      " [19.3]\n",
      " [13.1]\n",
      " [10.5]\n",
      " [37.2]\n",
      " [27.5]\n",
      " [17.8]\n",
      " [21. ]\n",
      " [33. ]\n",
      " [21.2]\n",
      " [ 8.4]\n",
      " [21.9]\n",
      " [23.1]\n",
      " [43.1]\n",
      " [23.5]\n",
      " [11.9]\n",
      " [22.2]\n",
      " [15.1]\n",
      " [18.3]\n",
      " [ 8.1]\n",
      " [26.2]\n",
      " [21. ]\n",
      " [14.3]\n",
      " [50. ]\n",
      " [19.9]\n",
      " [19. ]\n",
      " [21.7]\n",
      " [19.9]\n",
      " [35.4]\n",
      " [24.8]\n",
      " [13.8]\n",
      " [19.7]\n",
      " [33.3]\n",
      " [21.2]\n",
      " [31. ]\n",
      " [14.1]\n",
      " [13.3]\n",
      " [23.8]\n",
      " [20.1]\n",
      " [21.2]\n",
      " [36.1]\n",
      " [17.2]\n",
      " [19. ]\n",
      " [20.1]\n",
      " [22.6]\n",
      " [50. ]\n",
      " [26.6]\n",
      " [37. ]\n",
      " [22. ]\n",
      " [18. ]\n",
      " [41.3]\n",
      " [23.9]\n",
      " [23.7]\n",
      " [16.2]\n",
      " [24.8]\n",
      " [32.4]\n",
      " [18.7]\n",
      " [24.4]\n",
      " [50. ]\n",
      " [18.5]\n",
      " [21. ]\n",
      " [15.2]\n",
      " [24.8]\n",
      " [20.8]\n",
      " [25. ]\n",
      " [24.4]\n",
      " [ 9.5]\n",
      " [16.1]\n",
      " [19.3]\n",
      " [11.8]\n",
      " [23.1]\n",
      " [21.1]\n",
      " [22.8]\n",
      " [19.1]\n",
      " [19.4]\n",
      " [24.6]\n",
      " [34.6]\n",
      " [24.6]\n",
      " [ 5. ]\n",
      " [13.4]\n",
      " [23.7]\n",
      " [19.1]\n",
      " [37.3]\n",
      " [27.9]\n",
      " [21.2]\n",
      " [21.4]\n",
      " [22.4]\n",
      " [20.3]\n",
      " [29.4]\n",
      " [24.5]\n",
      " [17.2]\n",
      " [30.8]\n",
      " [36. ]\n",
      " [15.6]\n",
      " [23.8]\n",
      " [19.5]\n",
      " [30.1]\n",
      " [23.4]\n",
      " [17.1]\n",
      " [17.6]\n",
      " [19.5]\n",
      " [14.2]\n",
      " [12.5]\n",
      " [23.6]\n",
      " [18.6]\n",
      " [21.7]\n",
      " [50. ]\n",
      " [26.4]\n",
      " [18.9]\n",
      " [29.1]\n",
      " [19.4]\n",
      " [ 8.5]\n",
      " [12.8]\n",
      " [22.6]\n",
      " [20.4]\n",
      " [13.5]\n",
      " [48.5]\n",
      " [18.9]]\n",
      "Train iteration # 1 from a total 200\n",
      "Train iteration # 2 from a total 200\n",
      "Train iteration # 3 from a total 200\n",
      "Train iteration # 4 from a total 200\n",
      "Train iteration # 5 from a total 200\n",
      "Train iteration # 6 from a total 200\n",
      "Train iteration # 7 from a total 200\n",
      "Train iteration # 8 from a total 200\n",
      "Train iteration # 9 from a total 200\n",
      "Train iteration # 10 from a total 200\n",
      "Train iteration # 11 from a total 200\n",
      "Train iteration # 12 from a total 200\n",
      "Train iteration # 13 from a total 200\n",
      "Train iteration # 14 from a total 200\n",
      "Train iteration # 15 from a total 200\n",
      "Train iteration # 16 from a total 200\n",
      "Train iteration # 17 from a total 200\n",
      "Train iteration # 18 from a total 200\n",
      "Train iteration # 19 from a total 200\n",
      "Train iteration # 20 from a total 200\n",
      "Train iteration # 21 from a total 200\n",
      "Train iteration # 22 from a total 200\n",
      "Train iteration # 23 from a total 200\n",
      "Train iteration # 24 from a total 200\n",
      "Train iteration # 25 from a total 200\n",
      "Train iteration # 26 from a total 200\n",
      "Train iteration # 27 from a total 200\n",
      "Train iteration # 28 from a total 200\n",
      "Train iteration # 29 from a total 200\n",
      "Train iteration # 30 from a total 200\n",
      "Train iteration # 31 from a total 200\n",
      "Train iteration # 32 from a total 200\n",
      "Train iteration # 33 from a total 200\n",
      "Train iteration # 34 from a total 200\n",
      "Train iteration # 35 from a total 200\n",
      "Train iteration # 36 from a total 200\n",
      "Train iteration # 37 from a total 200\n",
      "Train iteration # 38 from a total 200\n",
      "Train iteration # 39 from a total 200\n",
      "Train iteration # 40 from a total 200\n",
      "Train iteration # 41 from a total 200\n",
      "Train iteration # 42 from a total 200\n",
      "Train iteration # 43 from a total 200\n",
      "Train iteration # 44 from a total 200\n",
      "Train iteration # 45 from a total 200\n",
      "Train iteration # 46 from a total 200\n",
      "Train iteration # 47 from a total 200\n",
      "Train iteration # 48 from a total 200\n",
      "Train iteration # 49 from a total 200\n",
      "Train iteration # 50 from a total 200\n",
      "Train iteration # 51 from a total 200\n",
      "Train iteration # 52 from a total 200\n",
      "Train iteration # 53 from a total 200\n",
      "Train iteration # 54 from a total 200\n",
      "Train iteration # 55 from a total 200\n",
      "Train iteration # 56 from a total 200\n",
      "Train iteration # 57 from a total 200\n",
      "Train iteration # 58 from a total 200\n",
      "Train iteration # 59 from a total 200\n",
      "Train iteration # 60 from a total 200\n",
      "Train iteration # 61 from a total 200\n",
      "Train iteration # 62 from a total 200\n",
      "Train iteration # 63 from a total 200\n",
      "Train iteration # 64 from a total 200\n",
      "Train iteration # 65 from a total 200\n",
      "Train iteration # 66 from a total 200\n",
      "Train iteration # 67 from a total 200\n",
      "Train iteration # 68 from a total 200\n",
      "Train iteration # 69 from a total 200\n",
      "Train iteration # 70 from a total 200\n",
      "Train iteration # 71 from a total 200\n",
      "Train iteration # 72 from a total 200\n",
      "Train iteration # 73 from a total 200\n",
      "Train iteration # 74 from a total 200\n",
      "Train iteration # 75 from a total 200\n",
      "Train iteration # 76 from a total 200\n",
      "Train iteration # 77 from a total 200\n",
      "Train iteration # 78 from a total 200\n",
      "Train iteration # 79 from a total 200\n",
      "Train iteration # 80 from a total 200\n",
      "Train iteration # 81 from a total 200\n",
      "Train iteration # 82 from a total 200\n",
      "Train iteration # 83 from a total 200\n",
      "Train iteration # 84 from a total 200\n",
      "Train iteration # 85 from a total 200\n",
      "Train iteration # 86 from a total 200\n",
      "Train iteration # 87 from a total 200\n",
      "Train iteration # 88 from a total 200\n",
      "Train iteration # 89 from a total 200\n",
      "Train iteration # 90 from a total 200\n",
      "Train iteration # 91 from a total 200\n",
      "Train iteration # 92 from a total 200\n",
      "Train iteration # 93 from a total 200\n",
      "Train iteration # 94 from a total 200\n",
      "Train iteration # 95 from a total 200\n",
      "Train iteration # 96 from a total 200\n",
      "Train iteration # 97 from a total 200\n",
      "Train iteration # 98 from a total 200\n",
      "Train iteration # 99 from a total 200\n",
      "Train iteration # 100 from a total 200\n",
      "Train iteration # 101 from a total 200\n",
      "Train iteration # 102 from a total 200\n",
      "Train iteration # 103 from a total 200\n",
      "Train iteration # 104 from a total 200\n",
      "Train iteration # 105 from a total 200\n",
      "Train iteration # 106 from a total 200\n",
      "Train iteration # 107 from a total 200\n",
      "Train iteration # 108 from a total 200\n",
      "Train iteration # 109 from a total 200\n",
      "Train iteration # 110 from a total 200\n",
      "Train iteration # 111 from a total 200\n",
      "Train iteration # 112 from a total 200\n",
      "Train iteration # 113 from a total 200\n",
      "Train iteration # 114 from a total 200\n",
      "Train iteration # 115 from a total 200\n",
      "Train iteration # 116 from a total 200\n",
      "Train iteration # 117 from a total 200\n",
      "Train iteration # 118 from a total 200\n",
      "Train iteration # 119 from a total 200\n",
      "Train iteration # 120 from a total 200\n",
      "Train iteration # 121 from a total 200\n",
      "Train iteration # 122 from a total 200\n",
      "Train iteration # 123 from a total 200\n",
      "Train iteration # 124 from a total 200\n",
      "Train iteration # 125 from a total 200\n",
      "Train iteration # 126 from a total 200\n",
      "Train iteration # 127 from a total 200\n",
      "Train iteration # 128 from a total 200\n",
      "Train iteration # 129 from a total 200\n",
      "Train iteration # 130 from a total 200\n",
      "Train iteration # 131 from a total 200\n",
      "Train iteration # 132 from a total 200\n",
      "Train iteration # 133 from a total 200\n",
      "Train iteration # 134 from a total 200\n",
      "Train iteration # 135 from a total 200\n",
      "Train iteration # 136 from a total 200\n",
      "Train iteration # 137 from a total 200\n",
      "Train iteration # 138 from a total 200\n",
      "Train iteration # 139 from a total 200\n",
      "Train iteration # 140 from a total 200\n",
      "Train iteration # 141 from a total 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iteration # 142 from a total 200\n",
      "Train iteration # 143 from a total 200\n",
      "Train iteration # 144 from a total 200\n",
      "Train iteration # 145 from a total 200\n",
      "Train iteration # 146 from a total 200\n",
      "Train iteration # 147 from a total 200\n",
      "Train iteration # 148 from a total 200\n",
      "Train iteration # 149 from a total 200\n",
      "Train iteration # 150 from a total 200\n",
      "Train iteration # 151 from a total 200\n",
      "Train iteration # 152 from a total 200\n",
      "Train iteration # 153 from a total 200\n",
      "Train iteration # 154 from a total 200\n",
      "Train iteration # 155 from a total 200\n",
      "Train iteration # 156 from a total 200\n",
      "Train iteration # 157 from a total 200\n",
      "Train iteration # 158 from a total 200\n",
      "Train iteration # 159 from a total 200\n",
      "Train iteration # 160 from a total 200\n",
      "Train iteration # 161 from a total 200\n",
      "Train iteration # 162 from a total 200\n",
      "Train iteration # 163 from a total 200\n",
      "Train iteration # 164 from a total 200\n",
      "Train iteration # 165 from a total 200\n",
      "Train iteration # 166 from a total 200\n",
      "Train iteration # 167 from a total 200\n",
      "Train iteration # 168 from a total 200\n",
      "Train iteration # 169 from a total 200\n",
      "Train iteration # 170 from a total 200\n",
      "Train iteration # 171 from a total 200\n",
      "Train iteration # 172 from a total 200\n",
      "Train iteration # 173 from a total 200\n",
      "Train iteration # 174 from a total 200\n",
      "Train iteration # 175 from a total 200\n",
      "Train iteration # 176 from a total 200\n",
      "Train iteration # 177 from a total 200\n",
      "Train iteration # 178 from a total 200\n",
      "Train iteration # 179 from a total 200\n",
      "Train iteration # 180 from a total 200\n",
      "Train iteration # 181 from a total 200\n",
      "Train iteration # 182 from a total 200\n",
      "Train iteration # 183 from a total 200\n",
      "Train iteration # 184 from a total 200\n",
      "Train iteration # 185 from a total 200\n",
      "Train iteration # 186 from a total 200\n",
      "Train iteration # 187 from a total 200\n",
      "Train iteration # 188 from a total 200\n",
      "Train iteration # 189 from a total 200\n",
      "Train iteration # 190 from a total 200\n",
      "Train iteration # 191 from a total 200\n",
      "Train iteration # 192 from a total 200\n",
      "Train iteration # 193 from a total 200\n",
      "Train iteration # 194 from a total 200\n",
      "Train iteration # 195 from a total 200\n",
      "Train iteration # 196 from a total 200\n",
      "Train iteration # 197 from a total 200\n",
      "Train iteration # 198 from a total 200\n",
      "Train iteration # 199 from a total 200\n",
      "Train iteration # 200 from a total 200\n",
      "[[22.46602341 14.30842328 31.99991745 ... 13.52431387 48.49742967\n",
      "  18.9       ]\n",
      " [22.41437277 14.30593156 31.99977251 ... 13.52571679 48.49666542\n",
      "  18.9       ]\n",
      " [22.36001085 14.30650537 31.99954489 ... 13.52674873 48.49575394\n",
      "  18.90000001]\n",
      " ...\n",
      " [22.54163857 13.62899996 33.50769664 ... 12.31898399 42.69944257\n",
      "  15.56954969]\n",
      " [22.54251789 13.62804392 33.51014544 ... 12.3186398  42.69498732\n",
      "  15.57006706]\n",
      " [22.54335676 13.62713718 33.51248378 ... 12.31831577 42.69073723\n",
      "  15.57056271]]\n",
      "Validation iteration # 1 from a total 200\n",
      "Validation iteration # 2 from a total 200\n",
      "Validation iteration # 3 from a total 200\n",
      "Validation iteration # 4 from a total 200\n",
      "Validation iteration # 5 from a total 200\n",
      "Validation iteration # 6 from a total 200\n",
      "Validation iteration # 7 from a total 200\n",
      "Validation iteration # 8 from a total 200\n",
      "Validation iteration # 9 from a total 200\n",
      "Validation iteration # 10 from a total 200\n",
      "Validation iteration # 11 from a total 200\n",
      "Validation iteration # 12 from a total 200\n",
      "Validation iteration # 13 from a total 200\n",
      "Validation iteration # 14 from a total 200\n",
      "Validation iteration # 15 from a total 200\n",
      "Validation iteration # 16 from a total 200\n",
      "Validation iteration # 17 from a total 200\n",
      "Validation iteration # 18 from a total 200\n",
      "Validation iteration # 19 from a total 200\n",
      "Validation iteration # 20 from a total 200\n",
      "Validation iteration # 21 from a total 200\n",
      "Validation iteration # 22 from a total 200\n",
      "Validation iteration # 23 from a total 200\n",
      "Validation iteration # 24 from a total 200\n",
      "Validation iteration # 25 from a total 200\n",
      "Validation iteration # 26 from a total 200\n",
      "Validation iteration # 27 from a total 200\n",
      "Validation iteration # 28 from a total 200\n",
      "Validation iteration # 29 from a total 200\n",
      "Validation iteration # 30 from a total 200\n",
      "Validation iteration # 31 from a total 200\n",
      "Validation iteration # 32 from a total 200\n",
      "Validation iteration # 33 from a total 200\n",
      "Validation iteration # 34 from a total 200\n",
      "Validation iteration # 35 from a total 200\n",
      "Validation iteration # 36 from a total 200\n",
      "Validation iteration # 37 from a total 200\n",
      "Validation iteration # 38 from a total 200\n",
      "Validation iteration # 39 from a total 200\n",
      "Validation iteration # 40 from a total 200\n",
      "Validation iteration # 41 from a total 200\n",
      "Validation iteration # 42 from a total 200\n",
      "Validation iteration # 43 from a total 200\n",
      "Validation iteration # 44 from a total 200\n",
      "Validation iteration # 45 from a total 200\n",
      "Validation iteration # 46 from a total 200\n",
      "Validation iteration # 47 from a total 200\n",
      "Validation iteration # 48 from a total 200\n",
      "Validation iteration # 49 from a total 200\n",
      "Validation iteration # 50 from a total 200\n",
      "Validation iteration # 51 from a total 200\n",
      "Validation iteration # 52 from a total 200\n",
      "Validation iteration # 53 from a total 200\n",
      "Validation iteration # 54 from a total 200\n",
      "Validation iteration # 55 from a total 200\n",
      "Validation iteration # 56 from a total 200\n",
      "Validation iteration # 57 from a total 200\n",
      "Validation iteration # 58 from a total 200\n",
      "Validation iteration # 59 from a total 200\n",
      "Validation iteration # 60 from a total 200\n",
      "Validation iteration # 61 from a total 200\n",
      "Validation iteration # 62 from a total 200\n",
      "Validation iteration # 63 from a total 200\n",
      "Validation iteration # 64 from a total 200\n",
      "Validation iteration # 65 from a total 200\n",
      "Validation iteration # 66 from a total 200\n",
      "Validation iteration # 67 from a total 200\n",
      "Validation iteration # 68 from a total 200\n",
      "Validation iteration # 69 from a total 200\n",
      "Validation iteration # 70 from a total 200\n",
      "Validation iteration # 71 from a total 200\n",
      "Validation iteration # 72 from a total 200\n",
      "Validation iteration # 73 from a total 200\n",
      "Validation iteration # 74 from a total 200\n",
      "Validation iteration # 75 from a total 200\n",
      "Validation iteration # 76 from a total 200\n",
      "Validation iteration # 77 from a total 200\n",
      "Validation iteration # 78 from a total 200\n",
      "Validation iteration # 79 from a total 200\n",
      "Validation iteration # 80 from a total 200\n",
      "Validation iteration # 81 from a total 200\n",
      "Validation iteration # 82 from a total 200\n",
      "Validation iteration # 83 from a total 200\n",
      "Validation iteration # 84 from a total 200\n",
      "Validation iteration # 85 from a total 200\n",
      "Validation iteration # 86 from a total 200\n",
      "Validation iteration # 87 from a total 200\n",
      "Validation iteration # 88 from a total 200\n",
      "Validation iteration # 89 from a total 200\n",
      "Validation iteration # 90 from a total 200\n",
      "Validation iteration # 91 from a total 200\n",
      "Validation iteration # 92 from a total 200\n",
      "Validation iteration # 93 from a total 200\n",
      "Validation iteration # 94 from a total 200\n",
      "Validation iteration # 95 from a total 200\n",
      "Validation iteration # 96 from a total 200\n",
      "Validation iteration # 97 from a total 200\n",
      "Validation iteration # 98 from a total 200\n",
      "Validation iteration # 99 from a total 200\n",
      "Validation iteration # 100 from a total 200\n",
      "Validation iteration # 101 from a total 200\n",
      "Validation iteration # 102 from a total 200\n",
      "Validation iteration # 103 from a total 200\n",
      "Validation iteration # 104 from a total 200\n",
      "Validation iteration # 105 from a total 200\n",
      "Validation iteration # 106 from a total 200\n",
      "Validation iteration # 107 from a total 200\n",
      "Validation iteration # 108 from a total 200\n",
      "Validation iteration # 109 from a total 200\n",
      "Validation iteration # 110 from a total 200\n",
      "Validation iteration # 111 from a total 200\n",
      "Validation iteration # 112 from a total 200\n",
      "Validation iteration # 113 from a total 200\n",
      "Validation iteration # 114 from a total 200\n",
      "Validation iteration # 115 from a total 200\n",
      "Validation iteration # 116 from a total 200\n",
      "Validation iteration # 117 from a total 200\n",
      "Validation iteration # 118 from a total 200\n",
      "Validation iteration # 119 from a total 200\n",
      "Validation iteration # 120 from a total 200\n",
      "Validation iteration # 121 from a total 200\n",
      "Validation iteration # 122 from a total 200\n",
      "Validation iteration # 123 from a total 200\n",
      "Validation iteration # 124 from a total 200\n",
      "Validation iteration # 125 from a total 200\n",
      "Validation iteration # 126 from a total 200\n",
      "Validation iteration # 127 from a total 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation iteration # 128 from a total 200\n",
      "Validation iteration # 129 from a total 200\n",
      "Validation iteration # 130 from a total 200\n",
      "Validation iteration # 131 from a total 200\n",
      "Validation iteration # 132 from a total 200\n",
      "Validation iteration # 133 from a total 200\n",
      "Validation iteration # 134 from a total 200\n",
      "Validation iteration # 135 from a total 200\n",
      "Validation iteration # 136 from a total 200\n",
      "Validation iteration # 137 from a total 200\n",
      "Validation iteration # 138 from a total 200\n",
      "Validation iteration # 139 from a total 200\n",
      "Validation iteration # 140 from a total 200\n",
      "Validation iteration # 141 from a total 200\n",
      "Validation iteration # 142 from a total 200\n",
      "Validation iteration # 143 from a total 200\n",
      "Validation iteration # 144 from a total 200\n",
      "Validation iteration # 145 from a total 200\n",
      "Validation iteration # 146 from a total 200\n",
      "Validation iteration # 147 from a total 200\n",
      "Validation iteration # 148 from a total 200\n",
      "Validation iteration # 149 from a total 200\n",
      "Validation iteration # 150 from a total 200\n",
      "Validation iteration # 151 from a total 200\n",
      "Validation iteration # 152 from a total 200\n",
      "Validation iteration # 153 from a total 200\n",
      "Validation iteration # 154 from a total 200\n",
      "Validation iteration # 155 from a total 200\n",
      "Validation iteration # 156 from a total 200\n",
      "Validation iteration # 157 from a total 200\n",
      "Validation iteration # 158 from a total 200\n",
      "Validation iteration # 159 from a total 200\n",
      "Validation iteration # 160 from a total 200\n",
      "Validation iteration # 161 from a total 200\n",
      "Validation iteration # 162 from a total 200\n",
      "Validation iteration # 163 from a total 200\n",
      "Validation iteration # 164 from a total 200\n",
      "Validation iteration # 165 from a total 200\n",
      "Validation iteration # 166 from a total 200\n",
      "Validation iteration # 167 from a total 200\n",
      "Validation iteration # 168 from a total 200\n",
      "Validation iteration # 169 from a total 200\n",
      "Validation iteration # 170 from a total 200\n",
      "Validation iteration # 171 from a total 200\n",
      "Validation iteration # 172 from a total 200\n",
      "Validation iteration # 173 from a total 200\n",
      "Validation iteration # 174 from a total 200\n",
      "Validation iteration # 175 from a total 200\n",
      "Validation iteration # 176 from a total 200\n",
      "Validation iteration # 177 from a total 200\n",
      "Validation iteration # 178 from a total 200\n",
      "Validation iteration # 179 from a total 200\n",
      "Validation iteration # 180 from a total 200\n",
      "Validation iteration # 181 from a total 200\n",
      "Validation iteration # 182 from a total 200\n",
      "Validation iteration # 183 from a total 200\n",
      "Validation iteration # 184 from a total 200\n",
      "Validation iteration # 185 from a total 200\n",
      "Validation iteration # 186 from a total 200\n",
      "Validation iteration # 187 from a total 200\n",
      "Validation iteration # 188 from a total 200\n",
      "Validation iteration # 189 from a total 200\n",
      "Validation iteration # 190 from a total 200\n",
      "Validation iteration # 191 from a total 200\n",
      "Validation iteration # 192 from a total 200\n",
      "Validation iteration # 193 from a total 200\n",
      "Validation iteration # 194 from a total 200\n",
      "Validation iteration # 195 from a total 200\n",
      "Validation iteration # 196 from a total 200\n",
      "Validation iteration # 197 from a total 200\n",
      "Validation iteration # 198 from a total 200\n",
      "Validation iteration # 199 from a total 200\n",
      "Validation iteration # 200 from a total 200\n",
      "(354, 1) (200, 354)\n",
      "[ 0.33651319  0.35863176  0.38157526  0.40536419  0.43003516  0.4556379\n",
      "  0.48223079  0.50987511  0.53862841  0.56853797  0.59963577  0.6319365\n",
      "  0.6654391   0.70013143  0.73599599  0.7730149   0.81117287  0.85045833\n",
      "  0.89086348  0.93238394  0.97501785  1.01876405  1.06361899  1.10957225\n",
      "  1.15660152  1.2046686   1.25371819  1.30368066  1.3544783   1.40603281\n",
      "  1.45827161  1.51113139  1.56455849  1.61850706  1.67293583  1.7278047\n",
      "  1.783072    1.83869299  1.89461969  1.95080183  2.00718842  2.06373005\n",
      "  2.12038138  2.17710375  2.23386741  2.29065266  2.34744967  2.40425647\n",
      "  2.46107522  2.51790726  2.57474742  2.6315787   2.68836833  2.74506607\n",
      "  2.80160506  2.8579055   2.91388014  2.96944082  3.02450472  3.07899917\n",
      "  3.13286469  3.18605589  3.23854095  3.29030035  3.34132561  3.3916187\n",
      "  3.4411919   3.49006782  3.53827899  3.58586675  3.63287951  3.67936996\n",
      "  3.72538987  3.7709818   3.81616819  3.86094087  3.90525463  3.94902786\n",
      "  3.99215173  4.03450767  4.07599107  4.1165351   4.15612531  4.19479691\n",
      "  4.23261476  4.26964602  4.305939    4.34151568  4.37637638  4.41051027\n",
      "  4.44390668  4.47656553  4.50850797  4.5397887   4.57050927  4.60082863\n",
      "  4.63096514  4.66118537  4.69177999  4.72303374  4.75519907  4.78848086\n",
      "  4.82303375  4.85896875  4.89636353  4.93527172  4.97572926  5.01775875\n",
      "  5.06137381  5.10658505  5.15340806  5.20187225  5.2520285   5.30395344\n",
      "  5.35774927  5.41353877  5.47145654  5.53163788  5.59420722  5.65926769\n",
      "  5.72689309  5.79712308  5.8699615   5.94537749  6.02330847  6.10366407\n",
      "  6.18633026  6.27117296  6.35804112  6.44676904  6.53717827  6.62907923\n",
      "  6.72227278  6.81655187  6.91170343  7.0075103   7.10375343  7.20021406\n",
      "  7.29667593  7.39292739  7.48876336  7.58398712  7.67841182  7.7718618\n",
      "  7.86417355  7.95519647  8.04479342  8.1328409   8.21922916  8.30386203\n",
      "  8.38665663  8.46754291  8.54646309  8.62337109  8.69823173  8.77102009\n",
      "  8.84172067  8.91032663  8.97683907  9.04126619  9.10362261  9.16392868\n",
      "  9.22220976  9.27849563  9.33281988  9.38521937  9.43573371  9.48440483\n",
      "  9.5312765   9.57639398  9.61980368  9.66155279  9.70168907  9.74026054\n",
      "  9.77731529  9.81290128  9.84706614  9.87985705  9.91132062  9.94150275\n",
      "  9.97044853  9.9982022  10.02480706 10.0503054  10.0747385  10.09814655\n",
      " 10.12056866 10.14204283 10.16260595 10.18229376 10.20114092 10.21918094\n",
      " 10.23644623 10.25296811 10.26877683 10.28390156 10.29837045 10.31221062\n",
      " 10.32544818 10.33810829] [30.26296109 28.42052182 26.45677894 24.4289747  22.40139806 20.43405707\n",
      " 18.57662093 16.87363881 15.36365519 14.0689903  12.99014506 12.10984838\n",
      " 11.40032283 10.82691002 10.35507219  9.95846589  9.61892453  9.32336679\n",
      "  9.06141716  8.82495597  8.60931855  8.41254897  8.23375145  8.07236419\n",
      "  7.92798636  7.80012739  7.68843794  7.59216737  7.50829234  7.43268049\n",
      "  7.36330766  7.3010327   7.24818084  7.2058724   7.17107938  7.13779624\n",
      "  7.10273693  7.06793936  7.03712001  7.01136276  6.98930172  6.96932008\n",
      "  6.95036296  6.9318378   6.91360379  6.89607516  6.88015337  6.86688988\n",
      "  6.85705542  6.85088849  6.8481229   6.84816392  6.85025019  6.8535448\n",
      "  6.85718342  6.86032248  6.86220256  6.86221302  6.85994036  6.85519265\n",
      "  6.84799358  6.8385431   6.82716148  6.81423933  6.80019919  6.78546686\n",
      "  6.77045335  6.75554743  6.741116    6.72750697  6.71504951  6.70404651\n",
      "  6.69475499  6.68735508  6.68191601  6.67837484  6.67654202  6.67613684\n",
      "  6.67684191  6.67835821  6.68044431  6.68292944  6.68569791  6.68865202\n",
      "  6.69167152  6.6945911   6.69720669  6.69930449  6.70069574  6.70124271\n",
      "  6.70087115  6.69957239  6.69740264  6.69448617  6.69102488  6.68730907\n",
      "  6.68371709  6.68069094  6.67868759  6.67812405  6.67934226  6.68260882\n",
      "  6.68814407  6.69616217  6.70690229  6.72063991  6.73767708  6.75831899\n",
      "  6.78284731  6.8114999   6.84446168  6.88186594  6.92380123  6.97031793\n",
      "  7.02143027  7.07711255  7.13729141  7.20183748  7.27056023  7.34320876\n",
      "  7.41947961  7.49903082  7.58149988  7.66652237  7.75374854  7.84285536\n",
      "  7.93355336  8.02558812  8.11873766  8.21280696  8.30762124  8.40301912\n",
      "  8.49884665  8.59495256  8.69118511  8.78739031  8.88341144  8.97908947\n",
      "  9.07426433  9.16877647  9.26246875  9.35518833  9.44678848  9.53713015\n",
      "  9.6260834   9.71352846  9.79935654  9.88347039  9.96578451 10.04622528\n",
      " 10.12473076 10.20125038 10.27574449 10.3481838  10.41854875 10.4868288\n",
      " 10.55302177 10.61713303 10.67917483 10.73916556 10.79712905 10.85309392\n",
      " 10.90709297 10.95916256 11.00934207 11.05767342 11.10420058 11.14896916\n",
      " 11.19202605 11.23341901 11.27319644 11.31140707 11.34809971 11.38332306\n",
      " 11.41712549 11.44955491 11.48065864 11.51048325 11.53907448 11.56647717\n",
      " 11.59273516 11.61789129 11.64198727 11.66506375 11.68716019 11.70831493\n",
      " 11.72856515 11.74794684 11.76649485 11.78424288 11.80122345 11.81746801\n",
      " 11.83300685 11.8478692  11.86208321 11.87567599 11.88867363 11.90110124\n",
      " 11.91298295 11.92434196]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    taus = np.logspace(1.0,3,200) #from 10 to 1000, 200 different taus\n",
    "    train_losses, test_losses = run_validation(x,y,taus,val_frac=0.3)\n",
    "    print(train_losses, test_losses)\n",
    "    plt.semilogx(taus, train_losses, label='train')\n",
    "    plt.semilogx(taus, test_losses, label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
